{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C047239 | GAT: Graph Attention Networks",
      "provenance": [],
      "authorship_tag": "ABX9TyOLEhrqYvohTfQXlRAgoew9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P11Yc9KImpmJ"
      },
      "source": [
        "# GAT\n",
        "\n",
        "> Graph Attention Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpbwYhbTmtRy"
      },
      "source": [
        "GATs work on graph data. A graph consists of nodes and edges connecting nodes. For example, in Cora dataset the nodes are research papers and the edges are citations that connect the papers.\n",
        "\n",
        "GAT uses masked self-attention, kind of similar to [transformers](https://nn.labml.ai/transformers/mha.html). GAT consists of graph attention layers stacked on top of each other. Each graph attention layer gets node embeddings as inputs and outputs transformed embeddings. The node embeddings pay attention to the embeddings of other nodes it’s connected to.\n",
        "\n",
        "The idea is to compute the hidden representations of each node in the graph, by attending over its neighbors, following a self-attention strategy. The attention architecture has several interesting properties: (1) the operation is efficient, since it is parallelizable across node neighbor pairs; (2) it can be applied to graph nodes having different degrees by specifying arbitrary weights to the neighbors; and (3) the model is directly applicable to inductive learning problems, including tasks where the model has to generalize to completely unseen graphs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u00yNYRRmx3S"
      },
      "source": [
        "<p><center><figure><img src='_images/C047239_1.png'><figcaption>An illustration of multi-head attention (with K = 3 heads) by node 1 on its neighborhood. Different arrow styles and colors denote independent attention computations. The aggregated features from each head are concatenated or averaged to obtain \\vec{h}'_1.</figcaption></figure></center></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfkqOx3Jm0RM"
      },
      "source": [
        "Formally,\n",
        "\n",
        "$$\\vec{h'}_i = \\sigma \\left( \\sum_{j \\in \\mathcal{N_i}} \\alpha_{ij}W\\vec{h}_j \\right)$$\n",
        "\n",
        "To stabilize the learning process of self-attention, we have found extending our mechanism to employ multi-head attention to be beneficial, similarly to Vaswani et al. (2017). Specifically, K independent attention mechanisms execute the transformation, and then their features are concatenated, resulting in the following output feature representation:\n",
        "\n",
        "$$\\vec{h'}_i = \\sigma \\left( \\frac{1}{K} \\sum_{k=1}^K \\sum_{j \\in \\mathcal{N_i}} \\alpha_{ij}^k W^k \\vec{h}_j \\right)$$\n",
        "\n",
        "If we perform multi-head attention on the final (prediction) layer of the network, concatenation is no longer sensible—instead, we employ averaging, and delay applying the final nonlinearity (usually a softmax or logistic sigmoid for classification problems) until then."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgKOZ1q7m0Ok"
      },
      "source": [
        "<p><center><figure><img src='_images/C047239_2.png'><figcaption>A t-SNE plot of the computed feature representations of a pre-trained GAT model’s first hidden layer on the Cora dataset. Node colors denote classes. Edge thickness indicates aggregated normalized attention coefficients between nodes i and j, across all eight attention heads (\\sum_{k=1}^K \\alpha_{ij}^k + \\alpha{ji}^k).</figcaption></figure></center></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRVfAlHNm0Mp"
      },
      "source": [
        "## References\n",
        "\n",
        "1. [https://youtu.be/uFLeKkXWq2c](https://youtu.be/uFLeKkXWq2c)\n",
        "2. https://nn.labml.ai/graphs/gat/index.html"
      ]
    }
  ]
}