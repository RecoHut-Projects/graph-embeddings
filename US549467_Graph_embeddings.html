
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Graph embeddings &#8212; graph-embeddings</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Key developments" href="L742313_Key_developments.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">graph-embeddings</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1 current">
  <a class="reference internal" href="#">
   Graph embeddings
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Concepts
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="L742313_Key_developments.html">
   Key developments
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L991141_Random_walk.html">
   Random walk
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L128493_Skip_gram_model.html">
   Skip-gram model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="L883045_Message_Passing_Neural_Networks.html">
   Message Passing Neural Networks
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="C870584_DeepWalk.html">
   DeepWalk
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="C067906_LINE.html">
   LINE
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/US549467_Graph_embeddings.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sparsh-ai/graph-embeddings/main?urlpath=lab/tree/docs/US549467_Graph_embeddings.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sparsh-ai/graph-embeddings/blob/main/docs/US549467_Graph_embeddings.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-generalized-network-embedding-problem">
   The generalized network embedding problem
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graph-level-embedding">
   Graph level embedding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#node-level-embedding">
   Node-level embedding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#edge-level-embedding">
   Edge level embedding
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#encoder-and-decoder">
   Encoder and Decoder
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#categorization-of-embedding-algorithms">
   Categorization of embedding algorithms
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#shallow-embedding-methods">
     Shallow embedding methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graph-autoencoding-methods">
     Graph autoencoding methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neighborhood-aggregation-methods">
     Neighborhood aggregation methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graph-regularization-methods">
     Graph regularization methods
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#graph-neural-networks">
     Graph neural networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   Shallow embedding methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graph-factorization">
   Graph factorization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   Graph autoencoding methods
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   Graph neural networks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spectral-graph-convolution">
   Spectral graph convolution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spatial-graph-convolution">
   Spatial graph convolution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#taxonomy">
   Taxonomy
  </a>
  <ul class="nav section-nav flex-column">
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="graph-embeddings">
<h1>Graph embeddings<a class="headerlink" href="#graph-embeddings" title="Permalink to this headline">¶</a></h1>
<p>Due to their nature, graphs can be analyzed at different levels of granularity: at the node, edge, and graph level (the whole graph), as depicted in the following figure. For each of those levels, different problems could be faced and, as a consequence, specific algorithms should be used.</p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_1.png?raw=1'><figcaption>Visual representation of the three different levels of granularity in graphs</figcaption></figure></center></p><p>The first, and most straightforward, way of creating features capable of representing structural information from graphs is the extraction of certain statistics. For instance, a graph could be represented by its degree distribution, efficiency, and other metrics.</p>
<p>A more complex procedure consists of applying specific kernel functions or, in other cases, engineering-specific features that are capable of incorporating the desired properties into the final machine learning model. However, as you can imagine, this process could be really time-consuming and, in certain cases, the features used in the model could represent just a subset of the information that is really needed to get the best performance for the final model.</p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_2.png?raw=1'><figcaption>Converting Adjacency Matrices to low-dimensional continuous vector spaces.</figcaption></figure></center></p><p>In the last decade, a lot of work has been done in order to define new approaches for creating meaningful and compact representations of graphs. The general idea behind all these approaches is to create algorithms capable of <em>learning</em> a good representation of the original dataset such that geometric relationships in the new space reflect the structure of the original graph. We usually call the process of learning a good representation of a given graph <strong>representation learning</strong> or <strong>network embedding.</strong></p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_3.png?raw=1'><figcaption>Example of a workflow for a network embedding algorithm</figcaption></figure></center></p><div class="section" id="the-generalized-network-embedding-problem">
<h2>The generalized network embedding problem<a class="headerlink" href="#the-generalized-network-embedding-problem" title="Permalink to this headline">¶</a></h2>
<p>Network embedding is the task that aims at learning a mapping function from a discrete graph to a continuous domain. Formally, given a graph <span class="math notranslate nohighlight">\(G = (V, E)\)</span> with weighted adjacency matrix <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{|V|×|V|}\)</span>, the goal is to learn low-dimensional vector representations <span class="math notranslate nohighlight">\({Z_i}_{\{i \in V\}}\)</span> (embeddings) for nodes in the graph <span class="math notranslate nohighlight">\({v_i}_{\{i \in V\}}\)</span>, such that important graph properties (e.g. local or global structure) are preserved in the embedding space. For instance, if two nodes have similar connections in the original graph, their learned vector representations should be close. Let <span class="math notranslate nohighlight">\(Z \in \mathbb{R}^{|V|×d}\)</span> denote the node embedding matrix. In practice, we often want low-dimensional embeddings (<span class="math notranslate nohighlight">\(d \ll |V|\)</span>) for scalability purposes. That is, network embedding can be viewed as a dimensionality reduction technique for graph structured data, where the input data is defined on a non-Euclidean, high-dimensional, discrete domain.</p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_8.png?raw=1'><figcaption>A general design pipeline of graph embedding-based recommendation. source.</figcaption></figure></center></p></div>
<div class="section" id="graph-level-embedding">
<h2>Graph level embedding<a class="headerlink" href="#graph-level-embedding" title="Permalink to this headline">¶</a></h2>
<p>Given a dataset with <em>m</em> different graphs, the task is to build a machine learning algorithm capable of classifying a graph into the right class. We can then see this problem as a classification problem, where the dataset is defined by a list of pairs, <span class="math notranslate nohighlight">\(*&lt;G_i,y_i&gt;*\)</span>, where <span class="math notranslate nohighlight">\(*G_i*\)</span> is a graph and <span class="math notranslate nohighlight">\(*y_i*\)</span> is the class the graph belongs to.</p>
<p>Representation learning (network embedding) is the task that aims to learn a mapping function <span class="math notranslate nohighlight">\(f:G \to \mathbb{R}^n\)</span>, from a discrete graph to a continuous domain. Function <span class="math notranslate nohighlight">\(f\)</span> will be capable of performing a low-dimensional vector representation such that the properties (local and global) of graph <span class="math notranslate nohighlight">\(G\)</span> are preserved.</p>
</div>
<div class="section" id="node-level-embedding">
<h2>Node-level embedding<a class="headerlink" href="#node-level-embedding" title="Permalink to this headline">¶</a></h2>
<p>Given a (possibly large) graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span>, the goal is to classify each vertex <span class="math notranslate nohighlight">\(v \in V\)</span> into the right class. In this setting, the dataset includes <span class="math notranslate nohighlight">\(*G*\)</span> and a list of pairs, <span class="math notranslate nohighlight">\(*&lt;v_i,y_i&gt;*\)</span>, where <span class="math notranslate nohighlight">\(*v_i*\)</span> is a node of graph <span class="math notranslate nohighlight">\(*G*\)</span> and <span class="math notranslate nohighlight">\(*y_i*\)</span> is the class to which the node belongs. In this case, the mapping function would be <span class="math notranslate nohighlight">\(f:V \to \mathbb{R}^n\)</span>.</p>
<p>The goal of node embedding is “efficient task-independent feature-learning for machine learning with graphs”.</p>
<p><center><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_4.png?raw=1'></center></p></div>
<div class="section" id="edge-level-embedding">
<h2>Edge level embedding<a class="headerlink" href="#edge-level-embedding" title="Permalink to this headline">¶</a></h2>
<p>Given a (possibly large) graph <span class="math notranslate nohighlight">\(G = (V,E)\)</span>, the goal is to classify each edge <span class="math notranslate nohighlight">\(e \in E\)</span>, into the right class. In this setting, the dataset includes <span class="math notranslate nohighlight">\(*G*\)</span> and a list of pairs, <span class="math notranslate nohighlight">\(*&lt;e_i,y_i&gt;*\)</span>, where <span class="math notranslate nohighlight">\(*e_i*\)</span> is an edge of graph <span class="math notranslate nohighlight">\(*G*\)</span> and <span class="math notranslate nohighlight">\(*y_i*\)</span> is the class to which the edge belongs. Another typical task for this level of granularity is <strong>link prediction</strong>, the problem of predicting the existence of a link between two existing nodes in a graph. In this case, the mapping function would be <span class="math notranslate nohighlight">\(f:E \to \mathbb{R}^n\)</span>.</p>
</div>
<div class="section" id="encoder-and-decoder">
<h2>Encoder and Decoder<a class="headerlink" href="#encoder-and-decoder" title="Permalink to this headline">¶</a></h2>
<p>Every graph, node, or edge embedding method can be described by two fundamental components, named the encoder and the decoder. The encoder (ENC) maps the input into the embedding space, while the decoder (DEC) decodes structural information about the graph from the learned embedding. It follows an intuitive idea: if we are able to encode a graph such that the decoder is able to retrieve all the necessary information, then the embedding must contain a compressed version of all this information and can be used to downstream machine learning tasks:</p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_5.png?raw=1'><figcaption>Generalized encoder (ENC) and decoder (DEC) architecture for embedding algorithms</figcaption></figure></center></p></div>
<div class="section" id="categorization-of-embedding-algorithms">
<h2>Categorization of embedding algorithms<a class="headerlink" href="#categorization-of-embedding-algorithms" title="Permalink to this headline">¶</a></h2>
<div class="section" id="shallow-embedding-methods">
<h3>Shallow embedding methods<a class="headerlink" href="#shallow-embedding-methods" title="Permalink to this headline">¶</a></h3>
<p>These methods are able to learn and return only the embedding values for the learned input data. Node2Vec, Edge2Vec, and Graph2Vec, which we previously discussed, are examples of shallow embedding methods. Indeed, they can only return a vectorial representation of the data they learned during the fit procedure. It is not possible to obtain the embedding vector for unseen data.</p>
</div>
<div class="section" id="graph-autoencoding-methods">
<h3>Graph autoencoding methods<a class="headerlink" href="#graph-autoencoding-methods" title="Permalink to this headline">¶</a></h3>
<p>These methods do not simply learn how to map the input graphs in vectors; they learn a more general mapping function, capable of also generating the embedding vector for unseen instances.</p>
</div>
<div class="section" id="neighborhood-aggregation-methods">
<h3>Neighborhood aggregation methods<a class="headerlink" href="#neighborhood-aggregation-methods" title="Permalink to this headline">¶</a></h3>
<p>These algorithms can be used to extract embeddings at the graph level, where nodes are labeled with some properties. Moreover, as for the graph autoencoding methods, the algorithms belonging to this class are able to learn a general mapping function, also capable of generating the embedding vector for unseen instances. A nice property of those algorithms is the possibility to build an embedding space where not only the internal structure of the graph is taken into account but also some external information, defined as properties of its nodes. For instance, with this method, we can have an embedding space capable of identifying, at the same time, graphs with similar structures and different properties on nodes.</p>
</div>
<div class="section" id="graph-regularization-methods">
<h3>Graph regularization methods<a class="headerlink" href="#graph-regularization-methods" title="Permalink to this headline">¶</a></h3>
<p>Methods based on graph regularization are slightly different from the ones listed in the preceding points. Here, we do not have a graph as input. Instead, the objective is to learn from a set of features by exploiting their “interaction” to regularize the process. In more detail, a graph can be constructed from the features by considering feature similarities. The main idea is based on the assumption that nearby nodes in a graph are likely to have the same labels. Therefore, the loss function is designed to constrain the labels to be consistent with the graph structure. For example, regularization might constrain neighboring nodes to share similar embeddings, in terms of their distance in the L2 norm. For this reason, the encoder only uses X node features as input.</p>
</div>
<div class="section" id="graph-neural-networks">
<h3>Graph neural networks<a class="headerlink" href="#graph-neural-networks" title="Permalink to this headline">¶</a></h3>
<p>GNNs are deep learning methods that work on graph-structured data. This family of methods is also known as geometric deep learning and is gaining increasing interest in a variety of applications, including social network analysis and computer graphics. The original formulation of GNN was proposed by Scarselli et al. back in 2009. It relies on the fact that each node can be described by its features and its neighborhood. Information coming from the neighborhood (which represents the concept of locality in the graph domain) can be aggregated and used to compute more complex and high-level features.</p>
<p><center><figure><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_6.png?raw=1'><figcaption>The hierarchical structure of the different unsupervised embedding algorithms</figcaption></figure></center></p><div class="tip admonition">
<p class="admonition-title">Note</p>
<p>It is important to highlight the main role that these algorithms play when we try to solve a machine learning problem on a graph. They can be used passively in order to transform a graph into a feature vector suitable for a classical machine learning algorithm or for data visualization tasks. But they can also be used actively during the learning process, where the machine learning algorithm finds a compact and meaningful solution to a specific problem.</p>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>Shallow embedding methods<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>These methods are able to learn and return only the embedding values for the learned input data. Generally speaking, all the unsupervised embedding algorithms based on matrix factorization use the same principle. They all factorize an input graph expressed as a matrix in different components (commonly knows as matrix factorization). The main difference between each method lies in the loss function used during the optimization process. Indeed, different loss functions allow creating an embedding space that emphasizes specific properties of the input graph.</p>
</div>
<div class="section" id="graph-factorization">
<h2>Graph factorization<a class="headerlink" href="#graph-factorization" title="Permalink to this headline">¶</a></h2>
<p>The GF algorithm was one of the first models to reach good computational performance in order to perform the node embedding of a given graph. The loss function used in this method was mainly designed to improve GF performances and scalability. Indeed, the solution generated by this method could be noisy. Moreover, it should be noted, by looking at its matrix factorization formulation, that GF performs a strong symmetric factorization. This property is particularly suitable for undirected graphs, where the adjacency matrix is symmetric, but could be a potential limitation for undirected graphs.</p>
</div>
<div class="section" id="id2">
<h2>Graph autoencoding methods<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem.</p>
<p>Autoencoders are an extremely powerful tool that can effectively help data scientists to deal with high-dimensional datasets. Although first presented around 30 years ago, in recent years, autoencoders have become more and more widespread in conjunction with the general rise of neural network-based algorithms. Besides allowing us to compact sparse representations, they can also be at the base of generative models, representing the first inception of the famous <strong>Generative Adversarial Network</strong> (<strong>GAN</strong>), which is, using the words of Geoffrey Hinton: <em>“The most interesting idea in the last 10 years in machine learning”.</em> An autoencoder is a neural network where the inputs and outputs are basically the same, but that is characterized by a small number of units in the hidden layer. Loosely speaking, it is a neural network that is trained to reconstruct its inputs using a significantly lower number of variables and/or degree of freedom.</p>
<p>Different from other techniques such as Principal Component Analysis (PCA) and matrix factorization, autoencoders can learn non-linear transformation thanks to the non-linear activation functions of their neurons. The encoder-decoder structure is then trained to minimize the ability of the full network to reconstruct the input. In order to completely specify an autoencoder, we need a loss function. The error between the inputs and the outputs can be computed using different metrics and indeed the choice of the correct form for the “reconstruction” error is a critical point when building an autoencoder. Some common choices for the loss functions that measure the reconstruction error are <strong>mean square error</strong>, <strong>mean absolute error</strong>, <strong>cross-entropy</strong>, and <strong>KL divergence</strong>.</p>
<p>Graph autoencoding methods do not simply learn how to map the input graphs in vectors; they learn a more general mapping function, capable of also generating the embedding vector for unseen instances. When applying autoencoders to graph structures, the input and output of the network should be a graph representation, as, for instance, the adjacency matrix. The reconstruction loss could then be defined as the Frobenius norm of the difference between the input and output matrices. However, when applying autoencoders to such graph structures and adjacency matrices, two critical issues arise:</p>
<ul class="simple">
<li><p>Whereas the presence of links indicates a relation or similarity between two vertices, their absence does not generally indicate a dissimilarity between vertices.</p></li>
<li><p>The adjacency matrix is extremely sparse and therefore the model will naturally tend to predict a 0 rather than a positive value.</p></li>
</ul>
<p>To address such peculiarities of graph structures, when defining the reconstruction loss, we need to penalize more errors done for the non-zero elements rather than that for zero elements.</p>
<p>Although very powerful, these graph autoencoders encounter some issues when dealing with large graphs. For these cases, the input of our autoencoder is one row of the adjacency matrix that has as many elements as the nodes in the network. In large networks, this size can easily be of the order of millions or tens of millions.</p>
</div>
<div class="section" id="id3">
<h2>Graph neural networks<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>GNNs are deep learning methods that work on graph-structured data. This family of methods is also known as geometric deep learning and is gaining increasing interest in a variety of applications, including social network analysis and computer graphics. The original formulation of GNN was proposed by Scarselli et al. back in 2009. It relies on the fact that each node can be described by its features and its neighborhood. Information coming from the neighborhood (which represents the concept of locality in the graph domain) can be aggregated and used to compute more complex and high-level features.</p>
<p>Starting from this first idea, several attempts have been made in recent years to re-address the problem of learning from graph data. In particular, variants of the previously described GNN have been proposed, with the aim of improving its representation learning capability. Some of them are specifically designed to process specific types of graphs (direct, indirect, weighted, unweighted, static, dynamic, and so on). Also, several modifications have been proposed for the propagation step (convolution, gate mechanisms, attention mechanisms, and skip connections, among others), with the aim of improving representation at different levels. Also, different training methods have been proposed to improve learning.</p>
<p>Graph Convolutional Neural Network (GCN)-based encoders are one of the most diffused variants of GNN for unsupervised learning. GCNs are GNN models inspired by many of the basic ideas behind CNN. Filter parameters are typically shared over all locations in the graph and several layers are concatenated to form a deep network.</p>
<p>There are essentially two types of convolutional operations for graph data, namely spectral approaches and non-spectral (spatial) approaches. The first, as the name suggests, defines convolution in the spectral domain (that is, decomposing graphs in a combination of simpler elements). Spatial convolution formulates the convolution as aggregating feature information from neighbors.</p>
</div>
<div class="section" id="spectral-graph-convolution">
<h2>Spectral graph convolution<a class="headerlink" href="#spectral-graph-convolution" title="Permalink to this headline">¶</a></h2>
<p>Spectral approaches are related to spectral graph theory, the study of the characteristics of a graph in relation to the characteristic polynomial, eigenvalues, and eigenvectors of the matrices associated with the graph. The convolution operation is defined as the multiplication of a signal (node features) by a kernel. In more detail, it is defined in the Fourier domain by determining the eigendecomposition of the graph Laplacian (think about the graph Laplacian as an adjacency matrix normalized in a special way).</p>
<p>Spectral graph convolution methods have achieved noteworthy results in many domains. However, they present some drawbacks. Consider, for example, a very big graph with billions of nodes: a spectral approach requires the graph to be processed simultaneously, which can be impractical from a computational point of view.</p>
<p>Furthermore, spectral convolution often assumes a fixed graph, leading to poor generalization capabilities on new, different graphs. To overcome these issues, spatial graph convolution represents an interesting alternative.</p>
</div>
<div class="section" id="spatial-graph-convolution">
<h2>Spatial graph convolution<a class="headerlink" href="#spatial-graph-convolution" title="Permalink to this headline">¶</a></h2>
<p>Spatial graph convolutional networks perform the operations directly on the graph by aggregating information from spatially close neighbors. Spatial convolution has many advantages: weights can be easily shared across a different location of the graph, leading to a good generalization capability on different graphs. Furthermore, the computation can be done by considering subsets of nodes instead of the entire graph, potentially improving computational efficiency.</p>
<p>GraphSAGE is one of the algorithms that implement spatial convolution. One of the main characteristics is its ability to scale over various types of networks. We can think of GraphSAGE as composed of three steps:</p>
<ol class="simple">
<li><p><strong>Neighborhood sampling</strong>: For each node in a graph, the first step is to find its k-neighborhood, where <em>k</em> is defined by the user for determining how many hops to consider (neighbors of neighbors).</p></li>
<li><p><strong>Aggregation</strong>: The second step is to aggregate, for each node, the node features describing the respective neighborhood. Various types of aggregation can be performed, including average, pooling (for example, taking the best feature according to certain criteria), or an even more complicated operation, such as using recurrent units (such as LSTM).</p></li>
<li><p><strong>Prediction</strong>: Each node is equipped with a simple neural network that learns how to perform predictions based on the aggregated features from the neighbors.</p></li>
</ol>
<p>GraphSAGE is often used in supervised settings. However, by adopting strategies such as using a similarity function as the target distance, it can also be effective for learning embedding without explicitly supervising the task.</p>
</div>
<div class="section" id="taxonomy">
<h2>Taxonomy<a class="headerlink" href="#taxonomy" title="Permalink to this headline">¶</a></h2>
<p><center><img src='https://github.com/sparsh-ai/graph-embeddings/blob/main/docs/_images/US549467_7.png?raw=1'></center></p><div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Concepts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="L742313_Key_developments.html">Key developments</a></li>
<li class="toctree-l1"><a class="reference internal" href="L991141_Random_walk.html">Random walk</a></li>
<li class="toctree-l1"><a class="reference internal" href="L128493_Skip_gram_model.html">Skip-gram model</a></li>
<li class="toctree-l1"><a class="reference internal" href="L883045_Message_Passing_Neural_Networks.html">Message Passing Neural Networks</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="C870584_DeepWalk.html">DeepWalk</a></li>
<li class="toctree-l1"><a class="reference internal" href="C067906_LINE.html">LINE</a></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sparsh-ai/graph-embeddings",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
     <div id="next">
        <a class="right-next" href="L742313_Key_developments.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Key developments</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Sparsh A.<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>